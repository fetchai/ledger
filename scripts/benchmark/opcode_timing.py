#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import csv
import subprocess
import numpy as np
from tabulate import tabulate

# csv files to be generated by vm_benchmarks
vm_benchmark_path = '../../cmake-build-release/libs/vm/benchmark/'
vm_benchmark_file = 'vm_benchmark.csv'
opcode_list_file = 'opcode_lists.csv'

# number of benchmark repetitions
run_benchmarks = True
make_plots = True
num_reps = 100

# selectively suppress benchmarks by setting environment variables to 'true'
os.environ['FETCH_VM_BENCHMARK_NO_BASIC'] = 'false'
os.environ['FETCH_VM_BENCHMARK_NO_OBJECT'] = 'false'
os.environ['FETCH_VM_BENCHMARK_NO_PRIM_OPS'] = 'false'
os.environ['FETCH_VM_BENCHMARK_NO_MATH'] = 'false'
os.environ['FETCH_VM_BENCHMARK_NO_ARRAY'] = 'false'
os.environ['FETCH_VM_BENCHMARK_NO_CRYPTO'] = 'false'

# delete old file if it exists
if run_benchmarks and os.path.exists(opcode_list_file):
    os.remove(opcode_list_file)

# run benchmarks
if run_benchmarks:
    stdout = subprocess.call([vm_benchmark_path + 'vm-benchmarks',
                              '--benchmark_out=' + vm_benchmark_file,
                              '--benchmark_out_format=csv',
                              '--benchmark_repetitions=' + str(num_reps),
                              '--benchmark_report_aggregates_only=true',
                              '--benchmark_display_aggregates_only=true'])

# read opcode lists and baseline bms
with open(opcode_list_file) as csvfile:
    csvreader = csv.reader(csvfile)
    oprows = [oprow for oprow in csvreader]

bm_names = {int(oprow[0]): oprow[1] for oprow in oprows}
bm_inds = {oprow[1]: int(oprow[0]) for oprow in oprows}
baseline_inds = {bm_inds[oprow[1]]: bm_inds[oprow[2]] for oprow in oprows}
opcodes = {int(oprow[0]): [int(opcode) for (i, opcode) in enumerate(oprow[3:])] for oprow in oprows}
num_benchmarks = len(bm_inds)

# read results in text format
with open(vm_benchmark_file) as csvfile:
    csvreader = csv.reader(csvfile)
    rows = [row for row in csvreader if 'Benchmark' in row[0]]


def index(row):
    return int(row[0].split('_')[0].split('/')[1])


# get cpu time stats (in ns) for each bm index
means = {index(row): float(row[3]) for row in rows if 'mean' in row[0]}
medians = {index(row): float(row[3]) for row in rows if 'median' in row[0]}
stddevs = {index(row): float(row[3]) for row in rows if 'stddev' in row[0]}

# compute net bm stats
net_means = {bm: means[bm] - means[baseline_inds[bm]] for bm in bm_inds.values()}
net_stderrs = {bm: (stddevs[bm] ** 2 + stddevs[baseline_inds[bm]] ** 2) ** 0.5 / num_reps ** 0.5 for bm in
               bm_inds.values()}

# initialize opcode dicts
net_opcodes = {}
ext_opcodes = {}

# make table out of net benchmark times, standard errors, and (net) opcodes
table = []
for bm in bm_inds.values():
    base_bm = baseline_inds[bm]

    # net stats
    bm_mean = net_means[bm]
    bm_stderr = net_stderrs[bm]

    # net opcodes
    bm_opcodes = opcodes[bm]
    base_opcodes = opcodes[base_bm].copy()
    net_opcodes[bm] = [x for x in bm_opcodes if x not in base_opcodes or base_opcodes.remove(x)]

    # check for extra opcodes (included in base_bm but not in bm)
    bm_opcodes_copy = bm_opcodes.copy()
    ext_opcodes[bm] = [x for x in base_opcodes if x not in bm_opcodes_copy or bm_opcodes_copy.remove(x)]

    table.append([bm_names[bm], bm_mean, bm_stderr, bm_opcodes, bm_names[base_bm], net_opcodes[bm]])

print('\n')
print(tabulate(table, headers=['Benchmark (' + str(num_reps) + ' reps)',
                               'Mean (ns)', 'Std error (ns)', 'Opcodes',
                               'Baseline', 'Net opcodes'], floatfmt=".2f"))

param_bm_types = ['String', 'Array', 'Update']
pfits = {}
fig = 0

# get linear fits for parameterized benchmarks
for param_bm_type in param_bm_types:

    type_bm_names = {ind: name for (ind, name) in bm_names.items() if param_bm_type in name}
    arr_bm_types = {bm.split(param_bm_type)[0] for bm in type_bm_names.values()}

    for arr_bm_type in arr_bm_types:
        type_inds = [ind for (ind, name) in type_bm_names.items() if arr_bm_type == name.split(param_bm_type)[0]]

        lengths = [int(type_bm_names[ind].split(param_bm_type)[1]) for ind in type_inds]
        times = [net_means[ind] for ind in type_inds]
        errs = [net_stderrs[ind] for ind in type_inds]

        # linear fit
        pfits[arr_bm_type + param_bm_type] = np.polyfit(np.array(lengths), np.array(times), 1)

        if make_plots:
            import benchmark_plots

            benchmark_plots.plot(lengths, times, err=errs, fig=fig, title=arr_bm_type + param_bm_type)
            fig += 1
