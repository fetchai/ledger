#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import csv
import subprocess
from tabulate import tabulate

# csv file to be generated by vm_benchmarks
vm_benchmark_path = '../../cmake-build-release/libs/vm/benchmark/'
vm_benchmark_file = 'vm_benchmark.csv'

# number of benchmark repetitions
run_benchmarks = True
num_reps = 20

# run benchmarks
if run_benchmarks:
  stdout = subprocess.call([vm_benchmark_path + 'vm-benchmarks',
                  '--benchmark_out=' + vm_benchmark_file,
                  '--benchmark_out_format=csv',
                  '--benchmark_repetitions=' + str(num_reps),
                  '--benchmark_report_aggregates_only=true',
                  '--benchmark_display_aggregates_only=true'])

# read results in text format
with open(vm_benchmark_file) as csvfile:
  csvreader = csv.reader(csvfile)
  rows = [row for row in csvreader if 'OpcodeBenchmark' in row[0]]  
     
# parse benchmark labels
labels = [row[0] for row in rows]
benchmarks = [label.split('_',1) for label in labels]    
benchmark_names = [bm[0] for (ind,bm) in enumerate(benchmarks) if ind % 3 == 0]
num_benchmarks = len(benchmark_names)

# identify the baseline benchmarks and types
base_bms = [[name,ind] for (ind,name) in enumerate(benchmark_names) if 'Base' in name]
base_types ={base_bm[0].split('/Base')[1] : base_bm[1] for base_bm in base_bms}

# identify the corresponding benchmarks by type
bms_by_type = {typ : [j for (j,name) in enumerate(benchmark_names) if list(base_types.keys())[i] in name and not 'Base' in name] \
               for (i,typ) in enumerate(list(base_types.keys()))}

# cpu time stats (in ns) 
means = [float(row[3]) for row in rows if 'mean' in row[0]]
medians = [float(row[3]) for row in rows if 'median' in row[0]]
stddevs = [float(row[3]) for row in rows if 'stddev' in row[0]]
        
# compute net benchmark times and standard errors in the means
table = []
for base_type in list(base_types.keys()):
  base_bm = base_types[base_type]
  for bm in bms_by_type[base_type]:
    bm_mean = means[bm] - means[base_bm]
    bm_stderr = (stddevs[bm]**2 + stddevs[base_bm]**2)**0.5/num_reps**0.5
    table.append([benchmark_names[bm], bm_mean, bm_stderr])

print('\n')
print(tabulate(table, headers = ['Benchmark (' + str(num_reps) + ' reps)','Mean (ns)','Std error (ns)'], floatfmt=".2f"))